{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_order(data, results):\n",
    "    segment = torch.from_numpy(data['segment'])[:, None, ..., None]\n",
    "    scatter_shape = [segment.shape[0], segment.max() + 1, *segment.shape[2:]]\n",
    "    obj_mask_true = torch.zeros(scatter_shape).scatter_(1, segment, 1).numpy().astype(np.float64)[:, :-1]\n",
    "    obj_shp_true = data['masks'][:, :-1]\n",
    "    binary_mat_true = np.zeros((obj_shp_true.shape[0], obj_shp_true.shape[1], obj_shp_true.shape[1]))\n",
    "    for i in range(obj_shp_true.shape[1] - 1):\n",
    "        for j in range(i + 1, obj_shp_true.shape[1]):\n",
    "            region = np.minimum(obj_shp_true[:, i], obj_shp_true[:, j])\n",
    "            area_i = (obj_mask_true[:, i] * region).reshape(region.shape[0], -1).sum(-1)\n",
    "            area_j = (obj_mask_true[:, j] * region).reshape(region.shape[0], -1).sum(-1)\n",
    "            binary_mat_true[:, i, j] = (area_i >= area_j) * 2 - 1\n",
    "    obj_mask_all = results['mask'][:, :, :-1]\n",
    "    order_cost_all = -(obj_mask_true[None, :, :, None] * obj_mask_all[:, :, None])\n",
    "    order_cost_all = order_cost_all.reshape(*order_cost_all.shape[:-3], -1).sum(-1)\n",
    "    order_all = []\n",
    "    for cost_list in order_cost_all:\n",
    "        order_list = []\n",
    "        for cost in cost_list:\n",
    "            _, cols = linear_sum_assignment(cost)\n",
    "            order_list.append(cols)\n",
    "        order_all.append(order_list)\n",
    "    order_all = np.array(order_all)\n",
    "    return order_all, binary_mat_true\n",
    "\n",
    "def compute_oca(data, results):\n",
    "    segment = data['segment']\n",
    "    seg_back = segment.max()\n",
    "    count_true = np.array([(np.unique(val) != seg_back).sum() for val in segment])\n",
    "    pres_all = results['pres']\n",
    "    count_pred = (pres_all[..., :-1] >= 0.5).sum(-1)\n",
    "    oca_all = (count_pred == count_true[None]).astype(np.float64)\n",
    "    return oca_all\n",
    "\n",
    "def compute_ooa(data, results, order_all, binary_mat_true):\n",
    "    obj_shp_true = data['masks'][:, :-1]\n",
    "    weights = np.zeros((obj_shp_true.shape[0], obj_shp_true.shape[1], obj_shp_true.shape[1]))\n",
    "    for i in range(obj_shp_true.shape[1] - 1):\n",
    "        for j in range(i + 1, obj_shp_true.shape[1]):\n",
    "            region = np.minimum(obj_shp_true[:, i], obj_shp_true[:, j])\n",
    "            weights[:, i, j] = region.reshape(region.shape[0], -1).sum(-1)\n",
    "    sum_weights = weights.reshape(weights.shape[0], -1).sum(-1)\n",
    "    ooa_all = []\n",
    "    for order in order_all:\n",
    "        binary_mat_pred = np.zeros(weights.shape)\n",
    "        for i in range(order.shape[1] - 1):\n",
    "            for j in range(i + 1, order.shape[1]):\n",
    "                binary_mat_pred[:, i, j] = (order[:, i] < order[:, j]) * 2 - 1\n",
    "        binary_mat = (binary_mat_true * binary_mat_pred) == 1\n",
    "        ooa_all.append((binary_mat * weights).reshape(weights.shape[0], -1).sum(-1))\n",
    "    ooa_all = np.array(ooa_all)\n",
    "    weights_all = sum_weights[None].repeat(ooa_all.shape[0], axis=0)\n",
    "    return ooa_all, weights_all\n",
    "\n",
    "def compute_ari_ami(data, results):\n",
    "    segment_true = data['segment']\n",
    "    overlap = data['overlap']\n",
    "    segment_sel = overlap >= 1\n",
    "    mask_all = results['mask']\n",
    "    outputs = {key: [] for key in ['ari_all', 'ari_obj', 'ami_all', 'ami_obj']}\n",
    "    for mask in mask_all:\n",
    "        segment_a = np.argmax(mask, axis=1).squeeze(-1)\n",
    "        segment_o = np.argmax(mask[:, :-1], axis=1).squeeze(-1)\n",
    "        sub_outputs = {key: [] for key in outputs}\n",
    "        for seg_true, seg_sel, seg_a, seg_o in zip(segment_true, segment_sel, segment_a, segment_o):\n",
    "            seg_a_true_sel = seg_true.reshape(-1)\n",
    "            seg_o_true_sel = seg_true[seg_sel]\n",
    "            seg_a_sel = seg_a.reshape(-1)\n",
    "            seg_o_sel = seg_o[seg_sel]\n",
    "            sub_outputs['ari_all'].append(adjusted_rand_score(seg_a_true_sel, seg_a_sel))\n",
    "            sub_outputs['ari_obj'].append(adjusted_rand_score(seg_o_true_sel, seg_o_sel))\n",
    "            sub_outputs['ami_all'].append(adjusted_mutual_info_score(seg_a_true_sel, seg_a_sel, average_method='arithmetic'))\n",
    "            sub_outputs['ami_obj'].append(adjusted_mutual_info_score(seg_o_true_sel, seg_o_sel, average_method='arithmetic'))\n",
    "        for key, val in sub_outputs.items():\n",
    "            outputs[key].append(val)\n",
    "    outputs = {key: np.array(val) for key, val in outputs.items()}\n",
    "    return outputs\n",
    "\n",
    "def select_by_order(val_all, order_all):\n",
    "    val_all_sel = []\n",
    "    for val_list, order_list in zip(val_all, order_all):\n",
    "        val_sel = np.array([val[order] for val, order in zip(val_list, order_list)])\n",
    "        val_sel = np.concatenate([val_sel, val_list[:, -1:]], axis=1)\n",
    "        val_all_sel.append(val_sel)\n",
    "    return np.array(val_all_sel)\n",
    "\n",
    "def compute_iou_f1(data, results, order_all, eps=1e-6):\n",
    "    obj_shp_true = data['masks'][:, :-1]\n",
    "    obj_shp_all = select_by_order(results['shp'], order_all)[:, :, :-1]\n",
    "    seg_true = obj_shp_true.reshape(*obj_shp_true.shape[:2], -1)\n",
    "    pres = (seg_true.max(-1) != 0).astype(np.float64)\n",
    "    sum_pres = pres.sum(-1)\n",
    "    outputs = {key: [] for key in ['iou', 'f1']}\n",
    "    for obj_shp in obj_shp_all:\n",
    "        seg_pred = obj_shp.reshape(*obj_shp.shape[:2], -1)\n",
    "        area_i = np.minimum(seg_true, seg_pred).sum(-1)\n",
    "        area_u = np.maximum(seg_true, seg_pred).sum(-1)\n",
    "        iou = area_i / np.clip(area_u, eps, None)\n",
    "        f1 = 2 * area_i / np.clip(area_i + area_u, eps, None)\n",
    "        outputs['iou'].append((iou * pres).sum(-1))\n",
    "        outputs['f1'].append((f1 * pres).sum(-1))\n",
    "    outputs = {key: (np.array(val), sum_pres[None].repeat(len(val), axis=0)) for key, val in outputs.items()}\n",
    "    return outputs\n",
    "\n",
    "def compute_metrics(name_data_list, out_name):\n",
    "    batch_size = 10\n",
    "    folder_out = 'output/outs'\n",
    "    folder_data = '../compositional-scene-representation-datasets'\n",
    "    phase_list = ['test', 'general']\n",
    "    metrics = {}\n",
    "    for name_data in name_data_list:\n",
    "        metrics[name_data] = {}\n",
    "        for phase in phase_list:\n",
    "            metrics[name_data][phase] = {}\n",
    "            offset = 0\n",
    "            while True:\n",
    "                offset_new = offset + batch_size\n",
    "                with h5py.File(os.path.join(folder_data, '{}.h5'.format(name_data)), 'r') as f:\n",
    "                    data = {key: f[phase][key][offset:offset_new] for key in f[phase]}\n",
    "                    for key, val in data.items():\n",
    "                        if key in ['segment', 'overlap']:\n",
    "                            data[key] = val.astype(np.int64)\n",
    "                        else:\n",
    "                            data[key] = val.astype(np.float64) / 255\n",
    "                if data['image'].shape[0] == 0:\n",
    "                    break\n",
    "                with h5py.File(os.path.join(folder_out, name_data, '{}.h5'.format(phase)), 'r') as f:\n",
    "                    results = {key: f[key][:, offset:offset_new] for key in f}\n",
    "                    results = {key: val / 255 if val.dtype == np.uint8 else val for key, val in results.items()}\n",
    "                order_all = results['order']\n",
    "                pres_all = results['pres']\n",
    "                score_all = (order_all - order_all.min() + 1) * pres_all[:, :, :-1]\n",
    "                order_all = np.argsort(-score_all, axis=2)\n",
    "                for key in ['mask', 'apc', 'shp', 'pres']:\n",
    "                    results[key] = select_by_order(results[key], order_all)\n",
    "                order_all, binary_mat_true = compute_order(data, results)\n",
    "                sub_metrics = {\n",
    "                    'oca': compute_oca(data, results),\n",
    "                    'ooa': compute_ooa(data, results, order_all, binary_mat_true),\n",
    "                }\n",
    "                sub_metrics.update(compute_ari_ami(data, results))\n",
    "                sub_metrics.update(compute_iou_f1(data, results, order_all))\n",
    "                for key, val in sub_metrics.items():\n",
    "                    if key in metrics[name_data][phase]:\n",
    "                        metrics[name_data][phase][key].append(val)\n",
    "                    else:\n",
    "                        metrics[name_data][phase][key] = [val]\n",
    "                offset = offset_new\n",
    "            for key, val in metrics[name_data][phase].items():\n",
    "                if isinstance(val[0], tuple):\n",
    "                    val = tuple([np.concatenate(n, axis=1) for n in zip(*val)])\n",
    "                    assert len(val) == 2\n",
    "                    val = val[0].mean(-1) / val[1].mean(-1)\n",
    "                else:\n",
    "                    val = np.concatenate(val, axis=1)\n",
    "                    val = val.mean(-1)\n",
    "                metrics[name_data][phase][key] = val\n",
    "    with open(out_name, 'wb') as f:\n",
    "        pickle.dump(metrics, f)\n",
    "    return\n",
    "\n",
    "name_data_list = ['mnist', 'dsprites', 'abstract', 'clevr', 'shop', 'gso']\n",
    "out_name = 'metrics.pkl'\n",
    "compute_metrics(name_data_list, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metrics.pkl', 'rb') as f:\n",
    "    metrics = pickle.load(f)\n",
    "for name_data in metrics:\n",
    "    print(name_data)\n",
    "    for phase in metrics[name_data]:\n",
    "        print(phase)\n",
    "        for key_list in [['ari_all', 'ami_all', 'ari_obj', 'ami_obj'], ['iou', 'f1', 'oca', 'ooa']]:\n",
    "            text_list = []\n",
    "            for key in key_list:\n",
    "                val = metrics[name_data][phase][key]\n",
    "                if val is None:\n",
    "                    text_list.append('{:<7}: {:<11}'.format(key, 'N/A'))\n",
    "                else:\n",
    "                    text_list.append('{:<7}: {:.3f}'.format(key, val.mean()) + '\\u00b1' + '{:.0e}'.format(val.std()))\n",
    "            text = (' ' * 8).join(text_list)\n",
    "            print(text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(data, results):\n",
    "    image = data['image']\n",
    "    recon = results['recon']\n",
    "    mse_all = np.square(image[None] - recon).reshape(recon.shape[0], -1).mean(-1)\n",
    "    return mse_all\n",
    "\n",
    "def compute_metrics_recon(name_data_list, out_name):\n",
    "    folder_out = 'output/outs'\n",
    "    folder_out_nc = '../SPACE_nc/output/outs'\n",
    "    folder_data = '../compositional-scene-representation-datasets'\n",
    "    phase_list = ['test', 'general']\n",
    "    metrics = {}\n",
    "    for name_data in name_data_list:\n",
    "        metrics[name_data] = {}\n",
    "        for phase in phase_list:\n",
    "            metrics[name_data][phase] = {}\n",
    "            with h5py.File(os.path.join(folder_data, '{}.h5'.format(name_data)), 'r') as f:\n",
    "                data = {key: f[phase][key][()] for key in ['image']}\n",
    "                for key, val in data.items():\n",
    "                    if key in ['segment', 'overlap']:\n",
    "                        data[key] = val.astype(np.int64)\n",
    "                    else:\n",
    "                        data[key] = val.astype(np.float64) / 255\n",
    "            with h5py.File(os.path.join(folder_out, name_data, '{}.h5'.format(phase)), 'r') as f:\n",
    "                results = {key: f[key][()] / 255 for key in ['recon']}\n",
    "            with h5py.File(os.path.join(folder_out_nc, name_data, '{}.h5'.format(phase)), 'r') as f:\n",
    "                results_nc = {key: f[key][()] / 255 for key in ['recon']}\n",
    "            metrics[name_data][phase]['mse'] = compute_mse(data, results)\n",
    "            metrics[name_data][phase]['mse_nc'] = compute_mse(data, results_nc)\n",
    "    with open(out_name, 'wb') as f:\n",
    "        pickle.dump(metrics, f)\n",
    "    return\n",
    "\n",
    "name_data_list = ['mnist', 'dsprites', 'abstract', 'clevr', 'shop', 'gso']\n",
    "out_name = 'metrics_recon.pkl'\n",
    "compute_metrics_recon(name_data_list, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_recon(out_name):\n",
    "    with open(out_name, 'rb') as f:\n",
    "        metrics = pickle.load(f)\n",
    "    for name_data in metrics:\n",
    "        print(name_data)\n",
    "        for phase in metrics[name_data]:\n",
    "            print(phase)\n",
    "            for key_list in [['mse', 'mse_nc']]:\n",
    "                text_list = []\n",
    "                for key in key_list:\n",
    "                    val = metrics[name_data][phase][key]\n",
    "                    if val is None:\n",
    "                        text_list.append('{:<7}: {:<11}'.format(key, 'N/A'))\n",
    "                    else:\n",
    "                        text_list.append('{:<7}: {:.2f}e-3'.format(key, val.mean() * 1e3) + '\\u00b1' + '{:.0e}'.format(val.std()))\n",
    "                text = (' ' * 8).join(text_list)\n",
    "                print(text)\n",
    "        print()\n",
    "    return\n",
    "\n",
    "print_metrics_recon('metrics_recon.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
